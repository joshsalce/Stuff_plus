{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31113ac7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybaseball import statcast, statcast_batter, playerid_lookup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data21_clus = pd.read_csv('Data/ClusteredData/Clustered2021.csv', low_memory = False)\n",
    "data22_clus = pd.read_csv('Data/ClusteredData/Clustered2022.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dab5b40",
   "metadata": {},
   "source": [
    "# Dataset Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc5120e",
   "metadata": {},
   "source": [
    "## First Pass, New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7daf063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to fill NaN values within groups\n",
    "def fillna_by_pitcher(df, cols):\n",
    "    '''\n",
    "    Description: Fills NA values (pitch metrics), applied by pitch type per pitcher\n",
    "    --------------------------------------------------------------------------------\n",
    "    Inputs: df, cols\n",
    "    \n",
    "    Returns: df\n",
    "        NA columns filled\n",
    "    '''\n",
    "    \n",
    "    # For each column, take mean of column within dataframe, fill NA values with mean\n",
    "    for i in cols:\n",
    "        mean = df[i].mean()\n",
    "        df[i].fillna(mean,inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28012f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_train_data(df):\n",
    "    '''\n",
    "    Description: Cleans training data, filters dataframe for relevant features, \n",
    "    removes non-pitches and fills in NA values for each unique pitch for all pitchers\n",
    "    --------------------------------------------------------------------------------\n",
    "    Inputs: df\n",
    "    \n",
    "    Returns: df_clean\n",
    "        Cleaned input df\n",
    "    '''\n",
    "    # Define relevant feature columns, values to remove, columns with NA values to fill\n",
    "    non_pitches = ['FA','PO','KN','EP']\n",
    "    \n",
    "    y = ['delta_run_exp']\n",
    "    \n",
    "    y_cats = ['description','bb_type']\n",
    "    \n",
    "    context_features = ['player_name','p_throws','batter','stand','pitch_type','pitch_number',\n",
    "            'home_team','game_date','game_pk','at_bat_number',\n",
    "            'balls','strikes']\n",
    "    \n",
    "    cont_features = ['release_speed','release_extension','effective_speed','release_spin_rate',\n",
    "            'release_pos_x', 'release_pos_y', 'release_pos_z','spin_axis', 'pfx_x', 'pfx_z',\n",
    "            'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az', 'sz_top', 'sz_bot','launch_speed','launch_angle']\n",
    "    \n",
    "    features = y + y_cats + context_features + cont_features\n",
    "    \n",
    "    # Drop: game_pk, player_name, batter, game_date\n",
    "\n",
    "    \n",
    "    # Filter Dataframe for features\n",
    "    df = df[features]\n",
    "    \n",
    "    # Remove pitchouts/non-pitches, pitches with 0 movement (Statcast errors)\n",
    "    df_filt = df[(~df.pitch_type.isin(non_pitches)) & ((df.pfx_x != 0.0) & (df.pfx_z != 0.0))]\n",
    "    \n",
    "    # Define columns to fill or drop if NA\n",
    "    fill_cols = ['release_speed','release_extension','effective_speed','release_spin_rate',\n",
    "                 'release_pos_x','release_pos_y','release_pos_z','spin_axis']\n",
    "\n",
    "    na_cols = ['delta_run_exp','pitch_type','pitch_number','pfx_x','pfx_z',\n",
    "               'release_pos_x', 'release_pos_y', 'release_pos_z', \n",
    "               'release_speed','release_extension','effective_speed','release_spin_rate',\n",
    "               'spin_axis','sz_top', 'sz_bot']\n",
    "    \n",
    "    # Fill in NA values for each pitch and pitcher with mean of each column for each unique \n",
    "    df_filled = df_filt.groupby(['player_name','pitch_type']).apply(fillna_by_pitcher, cols = fill_cols)\n",
    "    df_clean = df_filled.dropna(subset=na_cols)\n",
    "    \n",
    "    df_clean = df_clean[(~(df_clean.bb_type.notna())) | ((df_clean.bb_type.notna()) & \n",
    "              ((df_clean.launch_speed.notna()) & (df_clean.launch_angle.notna())))]\n",
    "    \n",
    "    df_clean = df_clean.replace('foul_tip','swinging_strike').replace(\n",
    "    'swinging_strike_blocked','swinging_strike').replace('blocked_ball','ball').replace(\n",
    "    'missed_bunt','swinging_strike').replace('bunt_foul_tip','swinging_strike').replace('foul_bunt','foul')\n",
    "        \n",
    "    df_clean = df_clean[~((df_clean.description == 'hit_into_play') & (df_clean.bb_type.isna()))]\n",
    "    \n",
    "    # OHC Base variables to 0 and 1\n",
    "    #df_clean[['on_1b','on_2b','on_3b']] = df_clean[['on_1b','on_2b','on_3b']].notna().astype(int)\n",
    "    \n",
    "    # Sort dataframe by pitches in chronological order, return\n",
    "    df_clean = df_clean.sort_values(['game_date','game_pk','at_bat_number','pitch_number'])\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77060430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_features(df, season_start):\n",
    "    '''\n",
    "    Description: Adds new features in dataframe\n",
    "        - inferred_axis: Inferred Spin Axis (SSW Effects)\n",
    "        - axis_diff: Difference of Inferred and Observed Spin Axis\n",
    "        - game_week: Change game date to week of season depending on start date of season\n",
    "        - pitch_count: Pitch # of outing for each outing per pitcher \n",
    "    --------------------------------------------------------------------------------\n",
    "    Inputs: df, season_start (str)\n",
    "    \n",
    "    Returns: df\n",
    "        Dataframe with new features added\n",
    "    '''\n",
    "    \n",
    "    # inferred_axis: 180 / pi * atan(pfx_z / pfx_x) + 90 (where pfx_x is < 0, add 180 degrees.)\n",
    "    df['inferred_axis'] = np.degrees(np.arctan(df['pfx_z'] / df['pfx_x'])) + 90\n",
    "    df.loc[df['pfx_x'] < 0, 'inferred_axis'] += 180\n",
    "    df['axis_diff'] = df['spin_axis'] - df['inferred_axis']\n",
    "    \n",
    "    # axis_diff: spin_axis - inferred_axis\n",
    "    \n",
    "    # Pitch Count: Cumulative pitch number of outing for pitcher\n",
    "    df['pitch_count'] = df.sort_values(\n",
    "    ['game_date','game_pk','at_bat_number','pitch_number']).groupby(\n",
    "    ['game_date','game_pk','player_name']).cumcount() + 1\n",
    "    \n",
    "    # Create game_week column, where week of season is taken from game_date in Savant\n",
    "    start_date = datetime.strptime(season_start, '%Y-%m-%d').date()\n",
    "    \n",
    "    df['datetime'] = pd.to_datetime(df['game_date'])\n",
    "    df['game_week'] = df.apply(lambda x: ((x['datetime'].date() - start_date).days // 7) + 1, axis = 1)\n",
    "    df = df.drop('datetime',axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4ba3fd",
   "metadata": {},
   "source": [
    "## Second Pass, New Features\n",
    "Note: Need first pass of new features before added second pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2311a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For \"noise\" around pitch trajectory, calculate a multivariate normal distribution\n",
    "# for each unique pitch thrown for each pitcher over a season\n",
    "\n",
    "# Note: Calculating multivariate distributions for eachn pitch per game is \n",
    "# both extremely computationally intensive, and each distribution unstable due to small samples\n",
    "# of each pitch per game\n",
    "\n",
    "# Note: Does not include axis_diff for this iteration\n",
    "\n",
    "def multivariate_normal_distribution(x):\n",
    "    '''\n",
    "    Description: Applied to each group, calculate multivariate normal distribution\n",
    "    for each row's continuous features with mean and covariance matrix\n",
    "    --------------------------------------------------------------------------------\n",
    "    Inputs: x (dataframe row, Series)\n",
    "    \n",
    "    Returns: mvn_dist, SciPy multivariate normal distribution\n",
    "    '''\n",
    "    \n",
    "    # Define all continuous features \n",
    "    cont_feats = ['release_speed','release_extension','effective_speed',\n",
    "    'release_spin_rate','release_pos_x', 'release_pos_y', 'release_pos_z',\n",
    "    'pfx_x', 'pfx_z', 'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az', 'spin_axis','inferred_axis','axis_diff']\n",
    "    \n",
    "    \n",
    "    # Extract the continuous variables\n",
    "    continuous_vars = x[cont_feats]  \n",
    "    \n",
    "    # Calculate the mean and covariance matrix for the continuous variables\n",
    "    mean = continuous_vars.mean()\n",
    "    cov_matrix = continuous_vars.cov().fillna(0) + (np.eye(continuous_vars.cov().shape[0]) * 1e-6)\n",
    "    \n",
    "    # Create a multivariate normal distribution object\n",
    "    mvn_dist = multivariate_normal(mean=mean, cov=cov_matrix, allow_singular=True)\n",
    "    \n",
    "    return mvn_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mahalanobis(x):\n",
    "    '''\n",
    "    Description: Calculates mahalanobis distance of each pitch's continuous features\n",
    "    from center, inverse covariance matrix of distribution\n",
    "    --------------------------------------------------------------------------------\n",
    "    Inputs: x (type Series)\n",
    "    \n",
    "    Returns: mahalanobis_distance (type float)\n",
    "    '''\n",
    "    # Defines distribution, continuous features\n",
    "    distribution = x[-1]\n",
    "    data = np.array(x[:-1])\n",
    "    \n",
    "    # Calculates distance\n",
    "    mahalanobis_distance= mahalanobis(data, distribution.mean, np.linalg.inv(distribution.cov))\n",
    "    return mahalanobis_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc8a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_diff_features(data):\n",
    "    '''\n",
    "    Description: Adds features of movement and velocity differentials for each pitch\n",
    "    based on primary pitch per batter handedness per outing\n",
    "    --------------------------------------------------------------------------------\n",
    "    Inputs: df\n",
    "    \n",
    "    Returns: full_data \n",
    "        DataFrame with movement, velocity differentials and mahalanobis distance \"noise\"\n",
    "        variables added\n",
    "    '''\n",
    "    \n",
    "    # Groups data by each game_date and pitcher, finds primary fastball (or primary pitch if no fastball)\n",
    "    primary_fb = data.groupby(['game_date','game_pk','stand','player_name']).agg({\n",
    "        'pitch_type': lambda x: x[x.isin(['FC','SI','FF'])].value_counts().idxmax() \n",
    "        if any(x.isin(['FC','SI','FF'])) \n",
    "        else x.value_counts().idxmax()\n",
    "    }).rename(columns={'pitch_type':'primary_pitch'})\n",
    "\n",
    "\n",
    "    # Merges training data with primary fastball, defines new columns of primary_pitch\n",
    "    primary_fb_data = data.merge(primary_fb.reset_index(), \n",
    "                                 left_on=['game_date','game_pk','stand','player_name','pitch_type'], \n",
    "                                 right_on=['game_date','game_pk','stand','player_name','primary_pitch'], \n",
    "                                 how='inner')\n",
    "\n",
    "    # Define velocity, movement variables to calculate differentials from primary pitch\n",
    "    velo_mvt_cols = ['release_speed','release_spin_rate','pfx_x', 'pfx_z', \n",
    "                     'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az', 'spin_axis', 'inferred_axis','axis_diff']\n",
    "\n",
    "    # Calculates mean for velocity, movement variables for each primary pitch for each pitcher per outing\n",
    "    primary_fb_means = primary_fb_data.groupby(['game_date','game_pk','stand','player_name','pitch_type']).agg({\n",
    "        i: 'mean' for i in velo_mvt_cols}).rename(columns = {\n",
    "        i: i + '_mean' for i in velo_mvt_cols\n",
    "    }).reset_index()\n",
    "    primary_fb_means = primary_fb_means.rename(columns={'pitch_type':'primary_pitch'})\n",
    "\n",
    "    # Merges training data with primary pitch mean data\n",
    "    data_merged = data.merge(primary_fb_means, \n",
    "                             on = ['game_date','game_pk','stand','player_name'], how = 'inner')\n",
    "\n",
    "    # Calculates all differentials for velocity and movenent profiles\n",
    "    data_merged['velo_diff'] = data_merged['release_speed'] - data_merged['release_speed_mean']\n",
    "    data_merged['spin_rate_diff'] = data_merged['release_spin_rate'] - data_merged['release_spin_rate_mean']\n",
    "    data_merged['pfx_x_diff'] = data_merged['pfx_x'] - data_merged['pfx_x_mean']\n",
    "    data_merged['pfx_z_diff'] = data_merged['pfx_z'] - data_merged['pfx_z_mean']\n",
    "    data_merged['vx0_diff'] = data_merged['vx0'] - data_merged['vx0_mean']\n",
    "    data_merged['vy0_diff'] = data_merged['vy0'] - data_merged['vy0_mean']\n",
    "    data_merged['vz0_diff'] = data_merged['vz0'] - data_merged['vz0_mean']\n",
    "    data_merged['ax_diff'] = data_merged['ax'] - data_merged['ax_mean']\n",
    "    data_merged['ay_diff'] = data_merged['ay'] - data_merged['ay_mean']\n",
    "    data_merged['az_diff'] = data_merged['az'] - data_merged['az_mean']\n",
    "    data_merged['spin_axis_diff'] = data_merged['spin_axis'] - data_merged['spin_axis_mean']\n",
    "    data_merged['inferred_axis_diff'] = data_merged['inferred_axis'] - data_merged['inferred_axis_mean']\n",
    "    data_merged['axis_diff_diff'] = data_merged['axis_diff'] - data_merged['axis_diff_mean']\n",
    "\n",
    "    # Drops all primary pitch velocity, movement mean columns\n",
    "    data_merged = data_merged.drop(['primary_pitch'] + [i + '_mean' for i in velo_mvt_cols],axis = 1)\n",
    "    \n",
    "    \n",
    "    cont_feats = ['release_speed','release_extension','effective_speed',\n",
    "    'release_spin_rate','release_pos_x', 'release_pos_y', 'release_pos_z',\n",
    "    'pfx_x', 'pfx_z', 'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az', 'spin_axis','inferred_axis','axis_diff']\n",
    "    \n",
    "    # Applies multivariate normal to all unique pitches for each pitcher per year(> 3000 pitches per year)\n",
    "    pitch_noise_groups = data.groupby(['player_name','pitch_type']).apply(\n",
    "        multivariate_normal_distribution).reset_index(name = 'MV_Dist')\n",
    "\n",
    "    # Merges dataframes of training data, dataframe with multivariate distributions,\n",
    "    # so each unique pitch's distribution included in column for each pitch in training data\n",
    "    full_data = data_merged.merge(pitch_noise_groups, on = ['player_name','pitch_type'], how = 'inner')\n",
    "\n",
    "    # Calculate mahalanobis distance for all unique pitch's continuous features based on \n",
    "    # center and inverse covariance matrix of each pitch's multivariate distribution\n",
    "    full_data['mahalanobis'] = full_data[cont_feats + ['MV_Dist']].apply(\n",
    "        calc_mahalanobis, axis = 1)\n",
    "\n",
    "    # Drops all multivariate normal distributions, contextual features used for grouping/sorting\n",
    "    full_data = full_data.drop(\n",
    "        ['MV_Dist','game_pk', 'player_name', 'batter', 'game_date', 'at_bat_number', 'pitch_number'],axis = 1)\n",
    "    \n",
    "    ord_cols = ['delta_run_exp', 'description', 'bb_type','p_throws', 'stand',\n",
    "       'home_team', 'balls', 'strikes', 'pitch_count', 'game_week',\n",
    "       'pitch_type',\n",
    "       'release_speed', 'release_extension', 'effective_speed',\n",
    "       'release_spin_rate', 'release_pos_x', 'release_pos_y', 'release_pos_z',\n",
    "       'spin_axis', 'pfx_x', 'pfx_z', 'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az',\n",
    "       'sz_top', 'sz_bot', 'inferred_axis', 'axis_diff', 'velo_diff',\n",
    "       'spin_rate_diff', 'pfx_x_diff', 'pfx_z_diff', 'vx0_diff', 'vy0_diff',\n",
    "       'vz0_diff', 'ax_diff', 'ay_diff', 'az_diff', 'spin_axis_diff',\n",
    "       'inferred_axis_diff', 'axis_diff_diff', 'mahalanobis', 'launch_speed','launch_angle']\n",
    "    \n",
    "    full_data = full_data[ord_cols]\n",
    "   \n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71f9fa3",
   "metadata": {},
   "source": [
    "### Build Training Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd326960",
   "metadata": {},
   "outputs": [],
   "source": [
    "test21 = pd.read_csv('Data/Statcast/statcast21.csv', low_memory = False)\n",
    "test22 = pd.read_csv('Data/Statcast/statcast22.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12759cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "merge_cols = ['delta_run_exp', 'p_throws','batter', 'stand', 'pitch_number',\n",
    "       'home_team', 'game_date', 'game_pk', 'at_bat_number', 'balls',\n",
    "       'strikes','player_name', 'events', 'description','launch_speed', 'launch_angle','bb_type']\n",
    "\n",
    "merged_cols = ['on_1b','on_2b','on_3b']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef33fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test21_filt = test21[merge_cols + merged_cols]\n",
    "test22_filt = test22[merge_cols + merged_cols]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7be6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data21_clus = data21_clus.merge(test21_filt, on =merge_cols, how = 'inner')\n",
    "data22_clus = data22_clus.merge(test22_filt, on =merge_cols, how = 'inner')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b80b54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add pitch differentials, noise feature\n",
    "data21_train = add_diff_features(data21_clus)\n",
    "data22_train = add_diff_features(data22_clus)\n",
    "\n",
    "# Build training dataset\n",
    "training_set = pd.concat([data21_train,data22_train])\n",
    "training_set.columns, len(training_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3139207",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_cols = ['delta_run_exp', 'description', 'bb_type','p_throws', 'stand',\n",
    "       'home_team', 'balls', 'strikes', 'pitch_count', 'game_week',\n",
    "       'pitch_type', \n",
    "       'release_speed', 'release_extension', 'effective_speed',\n",
    "       'release_spin_rate', 'release_pos_x', 'release_pos_y', 'release_pos_z',\n",
    "       'spin_axis', 'pfx_x', 'pfx_z', 'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az',\n",
    "       'sz_top', 'sz_bot', 'inferred_axis', 'axis_diff', 'velo_diff',\n",
    "       'spin_rate_diff', 'pfx_x_diff', 'pfx_z_diff', 'vx0_diff', 'vy0_diff',\n",
    "       'vz0_diff', 'ax_diff', 'ay_diff', 'az_diff', 'spin_axis_diff',\n",
    "       'inferred_axis_diff', 'axis_diff_diff', 'mahalanobis', 'launch_speed','launch_angle']\n",
    "\n",
    "len(ord_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fcf984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-order training dataset, write to csv file\n",
    "# Training set has no context-neutral run values\n",
    "training_set = training_set[ord_cols].reset_index(drop=True)\n",
    "training_set.to_csv('TrainingDataAll.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d435061",
   "metadata": {},
   "source": [
    "# Full Test Run, Dataset Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2794606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Import dataset of 2021 statcast data\n",
    "test_df = pd.read_csv('Data/Statcast/statcast21.csv')\n",
    "test_df_april = test_df[(test_df.game_date >= '2021-04-01') & (test_df.game_date <= '2021-05-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f788c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clean data, add additional features, pitch \"noise\" features\n",
    "test_df_april_clean = clean_train_data(test_df)\n",
    "test_df_clean = add_new_features(test_df_april_clean,'2021-04-01')\n",
    "test_df_train = add_diff_features(test_df_clean)\n",
    "test_df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a88a8ff",
   "metadata": {},
   "source": [
    "# Create Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51226b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training data (all)\n",
    "training_data = pd.read_csv('TrainingDataAll.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8276a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_id_cols(row):\n",
    "    '''\n",
    "    Description: Add swing/no-swing, contact/swinging-strike, foul/fair event columns for each  \n",
    "    row based on description values in pitch data\n",
    "    --------------------------------------------------------------------------------\n",
    "    Inputs: row\n",
    "    \n",
    "    Returns: row \n",
    "        DataFrame row with added swing, contact, foul event columns I.e. '<90_GB, 100_105_FB, >105_LD, etc.'\n",
    "    '''\n",
    "    \n",
    "    # Define, non-swing, contact, swstrikes, foul events\n",
    "    non_swings = ['ball','called_strike','hit_by_pitch','blocked_ball']\n",
    "    contact_events = ['foul', 'hit_into_play','foul_bunt']  \n",
    "    sw_strikes = ['swinging_strike','foul_tip','bunt_foul_tip', 'missed_bunt', 'swinging_strike_blocked']\n",
    "    foul_events = ['foul', 'foul_bunt']  \n",
    "    \n",
    "    # If a non-swing event, create no swing column\n",
    "    if row['description'] in non_swings:\n",
    "        # no-swing value\n",
    "        swing_event = 'no_swing'\n",
    "        # Standardize description for context-neutral run values\n",
    "        row['description'] = row['description'].replace('blocked_ball', 'ball')\n",
    "        row['description'] = row['description'].replace('called_strike', 'strike')\n",
    "    else:\n",
    "        # swing value\n",
    "        swing_event = 'swing'\n",
    "\n",
    "    # If a swinging strike or contact event, create contact event column\n",
    "    if row['description'] in sw_strikes:\n",
    "        # swinging_strike value, standardize description\n",
    "        contact_event = 'swinging_strike'\n",
    "        row['description'] = 'strike'\n",
    "    elif row['description'] in contact_events:\n",
    "        # Contact\n",
    "        contact_event = 'contact'\n",
    "    else:\n",
    "        # If neither swinging strike nor contact, i.e. ball, HBP\n",
    "        contact_event = np.nan\n",
    "        \n",
    "    # If contact is made, create foul/fair event column\n",
    "    if row['description'] in foul_events:\n",
    "        # Foul Event, standardize description to foul balls only\n",
    "        foul_event = 'foul'\n",
    "        row['description'] = row['description'].replace('foul_bunt', 'foul')\n",
    "    elif row['description'] == 'hit_into_play':\n",
    "        # Fair Event\n",
    "        foul_event = 'fair'\n",
    "    else:\n",
    "        # If no contact is made\n",
    "        foul_event = np.nan\n",
    "\n",
    "    # Add all events to series, return row with series appended\n",
    "    events = pd.Series({'Swing_Event': swing_event, 'Contact_Event': contact_event,'Foul_Event': foul_event})\n",
    "    return row.append(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a8062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_la_ev_bucket(row):\n",
    "    '''\n",
    "    Description: Add la/ev bucket column value for each row based on bb_type, \n",
    "    launch_speed values in pitch data\n",
    "    --------------------------------------------------------------------------------\n",
    "    Inputs: row\n",
    "    \n",
    "    Returns: row \n",
    "        DataFrame row with added category str of bb_type/la bucket + ev_bucket\n",
    "    '''\n",
    "    \n",
    "    # Define batted-ball types\n",
    "    gb = row['bb_type'] == 'ground_ball'\n",
    "    ld = row['bb_type'] == 'line_drive'\n",
    "    fb = row['bb_type'] == 'fly_ball'\n",
    "    pu = row['bb_type'] == 'popup'\n",
    "    \n",
    "    # Define EV bucket ranges (< 90, 90 < x < 95, etc.)\n",
    "    less_90 = row['launch_speed'] < 90.0\n",
    "    betw_90_95 = row['launch_speed'] >= 90.0 and row['launch_speed'] < 95.0\n",
    "    betw_95_100 = row['launch_speed'] >= 95.0 and row['launch_speed'] < 100.0\n",
    "    betw_100_105 = row['launch_speed'] >= 100.0 and row['launch_speed'] < 105.0\n",
    "    greater_105 = row['launch_speed'] >= 105.0\n",
    "    \n",
    "    # If gb, lb, fb, pp batted-ball type\n",
    "    if gb:\n",
    "        # Else-IF logic for each EV bucket\n",
    "        if less_90:\n",
    "            category = '<90_GB'\n",
    "        elif betw_90_95:\n",
    "            category = '90_95_GB'\n",
    "        elif betw_95_100:\n",
    "            category = '95_100_GB'\n",
    "        elif betw_100_105:\n",
    "            category = '100_105_GB'\n",
    "        elif greater_105:\n",
    "             category = '>105_GB'\n",
    "    elif ld:\n",
    "        if less_90:\n",
    "            category = '<90_LD'\n",
    "        elif betw_90_95:\n",
    "            category = '90_95_LD'\n",
    "        elif betw_95_100:\n",
    "            category = '95_100_LD'\n",
    "        elif betw_100_105:\n",
    "            category = '100_105_LD'\n",
    "        elif greater_105:\n",
    "             category = '>105_LD'\n",
    "    elif fb:\n",
    "        if less_90:\n",
    "            category = '<90_FB'\n",
    "        elif betw_90_95:\n",
    "            category = '90_95_FB'\n",
    "        elif betw_95_100:\n",
    "            category = '95_100_FB'\n",
    "        elif betw_100_105:\n",
    "            category = '100_105_FB'\n",
    "        elif greater_105:\n",
    "             category = '>105_FB'\n",
    "    elif pu:\n",
    "        if less_90:\n",
    "            category = '<90_PU'\n",
    "        elif betw_90_95:\n",
    "            category = '90_95_PU'\n",
    "        elif betw_95_100:\n",
    "            category = '95_100_PU'\n",
    "        elif betw_100_105:\n",
    "            category = '100_105_PU'\n",
    "        elif greater_105:\n",
    "             category = '>105_PU'\n",
    "    else:\n",
    "        category = np.nan\n",
    "    \n",
    "    # Define series for la/ev bucket, append new column to row\n",
    "    la_ev_bucket = pd.Series({'LA_EV': category})\n",
    "    return row.append(la_ev_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f34ce7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add columns for contact event, foul/fair, in-play event, la/ev bucket\n",
    "train_data_labelled = training_data.apply(add_id_cols, axis=1).apply(add_la_ev_bucket, axis=1)\n",
    "train_data_labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d3ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv file, (w/o context-neutral run values)\n",
    "train_data_labelled.to_csv('TrainingDataLabelled.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c82732",
   "metadata": {},
   "source": [
    "# Splitting Data by Sub-Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33926f3b",
   "metadata": {},
   "source": [
    "Pitch Type\n",
    "- Fastballs\n",
    "- Offspeed\n",
    "- Breaking Balls\n",
    "\n",
    "Events\n",
    "- Swing/No Swing Events\n",
    "- Contact/No Contact Events\n",
    "- Foul/Fair Ball Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89892264",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('TrainingDataLabelled.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ef90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define irrelevant columns to drop for each dataset/model combination\n",
    "# I.e. in-play dataset/model do not need swing, contact, or foul event columns\n",
    "\n",
    "swing_drop_cols = ['delta_run_exp','bb_type','description','launch_speed',\n",
    "             'launch_angle','Contact_Event','Foul_Event','LA_EV']\n",
    "\n",
    "no_swing_drop_cols = ['delta_run_exp','bb_type','launch_speed',\n",
    "             'launch_angle','Swing_Event','Contact_Event','Foul_Event','LA_EV']\n",
    "\n",
    "contact_drop_cols = ['delta_run_exp','bb_type','description','launch_speed',\n",
    "             'launch_angle','Swing_Event','Foul_Event','LA_EV']\n",
    "\n",
    "foul_drop_cols = ['delta_run_exp','bb_type','description','launch_speed',\n",
    "             'launch_angle','Swing_Event','Contact_Event','LA_EV']\n",
    "\n",
    "in_play_drop_cols = ['delta_run_exp','bb_type','description','launch_speed',\n",
    "             'launch_angle','Swing_Event','Contact_Event','Foul_Event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce465f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data by pitch class, create datasets for each sub-model for each class \n",
    "fastballs = all_data[all_data.pitch_type.isin(['FF','SI','FC'])]\n",
    "offspeeds = all_data[all_data.pitch_type.isin(['CH','FS'])]\n",
    "breaking_balls = all_data[all_data.pitch_type.isin(['SL','KC','CU','ST','SV','CS'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ac9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fastballs_swing = fastballs.drop(swing_drop_cols,axis=1)\n",
    "#fastballs_no_swing = fastballs[fastballs.Swing_Event == 'no_swing'].drop(no_swing_drop_cols,axis=1)\n",
    "fastballs_contact = fastballs[fastballs.Contact_Event.notna()].drop(\n",
    "    contact_drop_cols,axis=1)\n",
    "fastballs_foul = fastballs[fastballs.Foul_Event.notna()].drop(\n",
    "    foul_drop_cols,axis=1)\n",
    "fastballs_in_play = fastballs[fastballs.Foul_Event == 'fair'].drop(\n",
    "    in_play_drop_cols,axis=1)\n",
    "\n",
    "fastballs_contact.to_csv('Data/Models/Contact_Models/Stuff_FB_Contact.csv',index = False)\n",
    "fastballs_foul.to_csv('Data/Models/Foul_Models/Stuff_FB_Foul.csv',index = False)\n",
    "fastballs_in_play.to_csv('Data/Models/In_Play_Models/Stuff_FB_InPlay.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90870eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#offspeeds_swing = offspeeds.drop(swing_drop_cols,axis=1)\n",
    "#offspeeds_no_swing = offspeeds[offspeeds.Swing_Event == 'no_swing'].drop(no_swing_drop_cols,axis=1)\n",
    "offspeeds_contact = offspeeds[offspeeds.Contact_Event.notna()].drop(\n",
    "    contact_drop_cols,axis=1)\n",
    "offspeeds_foul = offspeeds[offspeeds.Foul_Event.notna()].drop(\n",
    "    foul_drop_cols,axis=1)\n",
    "offspeeds_in_play = offspeeds[offspeeds.Foul_Event == 'fair'].drop(\n",
    "    in_play_drop_cols,axis=1)\n",
    "\n",
    "offspeeds_contact.to_csv('Data/Models/Contact_Models/Stuff_OS_Contact.csv',index = False)\n",
    "offspeeds_foul.to_csv('Data/Models/Foul_Models/Stuff_OS_Foul.csv',index = False)\n",
    "offspeeds_in_play.to_csv('Data/Models/In_Play_Models/Stuff_OS_InPlay.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#breaking_balls_swing = breaking_balls.drop(swing_drop_cols,axis=1)\n",
    "#breaking_balls_no_swing = breaking_balls[breaking_balls.Swing_Event == 'no_swing'].drop(no_swing_drop_cols,axis=1)\n",
    "breaking_balls_contact = breaking_balls[breaking_balls.Contact_Event.notna()].drop(\n",
    "    contact_drop_cols,axis=1)\n",
    "breaking_balls_foul = breaking_balls[breaking_balls.Foul_Event.notna()].drop(\n",
    "    foul_drop_cols,axis=1)\n",
    "breaking_balls_in_play = breaking_balls[breaking_balls.Foul_Event == 'fair'].drop(\n",
    "    in_play_drop_cols,axis=1)\n",
    "\n",
    "breaking_balls_contact.to_csv('Data/Models/Contact_Models/Stuff_BrBall_Contact.csv',index = False)\n",
    "breaking_balls_foul.to_csv('Data/Models/Foul_Models/Stuff_BrBall_Foul.csv',index = False)\n",
    "breaking_balls_in_play.to_csv('Data/Models/In_Play_Models/Stuff_BrBall_InPlay.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc44ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
